{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from lib.eeg_functions import *\n",
    "from lib.biggan_functions import *\n",
    "from scipy.fftpack import fft, rfft, fftfreq, irfft, ifft, rfftfreq\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define options\n",
    "opt = {}\n",
    "\n",
    "# Filtering options\n",
    "opt['detrend'] = True\n",
    "opt['ft-low'] = 0 #15\n",
    "opt['ft-high'] = 257 #70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated chunks: (800, 257, 35)\n",
      "Read latent values df: (800, 1123)\n",
      "Set success\n",
      "latent z: (800, 120) latent y: (800, 40)\n"
     ]
    }
   ],
   "source": [
    "# Defining modifiable parameters and options\n",
    "OPTION = 5\n",
    "NUM_INTERVALS = 40\n",
    "NUM_SAMPLES_PER_INTERVAL = 20\n",
    "CHUNK_SIZE_CHOSEN = 257\n",
    "\n",
    "Z_LENGTH = 120\n",
    "Y_LENGTH = 40 # 1000\n",
    "\n",
    "\n",
    "# EEG chunks for each image\n",
    "EEG_FILENAME = 'data/averaged_eeg_chunks.csv'\n",
    "\n",
    "NUM_IMAGES = NUM_INTERVALS * NUM_SAMPLES_PER_INTERVAL\n",
    "separated_chunks_array = read_eeg_from_file(EEG_FILENAME, NUM_IMAGES, CHUNK_SIZE_CHOSEN)\n",
    "print('Separated chunks:', separated_chunks_array.shape)\n",
    "\n",
    "\n",
    "# Latent representation of each image\n",
    "FILENAME = 'data/df_latent_values.csv'\n",
    "DF_LATENT_VALUES_READ = pd.read_csv(FILENAME, index_col = 0)\n",
    "DF_LATENT_VALUES_READ = DF_LATENT_VALUES_READ[:NUM_IMAGES] # selecting subset if not using all\n",
    "print('Read latent values df:', DF_LATENT_VALUES_READ.shape)\n",
    "\n",
    "\n",
    "bgf = biggan_functions()\n",
    "# Convert latent representation to array for NN\n",
    "latent_z, latent_y = bgf.convert_latent_to_array(Z_LENGTH, Y_LENGTH, DF_LATENT_VALUES_READ)\n",
    "print('latent z:', latent_z.shape, 'latent y:', latent_y.shape)\n",
    "\n",
    "# We are folding each image data into layer of frames. Thus, one image is present only in one 3D convolution, \n",
    "# does not span across multiple structures\n",
    "NUM_FRAMES = 6\n",
    "FRAME_SIZE = int(CHUNK_SIZE_CHOSEN/NUM_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 257, 35) (800, 40) (800, 120)\n"
     ]
    }
   ],
   "source": [
    "eeg = separated_chunks_array\n",
    "a,b,c = eeg.shape\n",
    "\n",
    "# Standardise\n",
    "mean = np.mean(eeg, 0)\n",
    "stddev = np.std(eeg, 0)\n",
    "eeg = (eeg - mean)/stddev\n",
    "print(eeg.shape, latent_y.shape, latent_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 258, 32)\n"
     ]
    }
   ],
   "source": [
    "# convert 35 channels to 32 channels\n",
    "# another option is to use linear embedding for dimension consistency\n",
    "_1_eeg = np.array([np.vstack((np.ones((1,35)), eeg[i])) for i in range(800)])\n",
    "avg_first_3 = np.mean(_1_eeg[:,:,0:3], 2, keepdims=True)\n",
    "avg_last_2 = np.mean(_1_eeg[:,:,-2:], 2, keepdims=True)\n",
    "avg_eeg = np.array([np.hstack((avg_first_3[i], _1_eeg[i,:,3:-2])) for i in range(800)])\n",
    "avg_eeg = np.array([np.hstack((avg_eeg[i], avg_last_2[i])) for i in range(800)])\n",
    "print(avg_eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 258, 32])\n"
     ]
    }
   ],
   "source": [
    "# Time axis\n",
    "a,b,c = avg_eeg.shape\n",
    "N = b\n",
    "T = 1.0/1000.0\n",
    "time = np.linspace(0.0, N*T, N)\n",
    "\n",
    "# Frequency axis\n",
    "w = rfftfreq(N, T)\n",
    "# FFT\n",
    "avg_eeg_fft = rfft(avg_eeg)\n",
    "\n",
    "# Notch Filter: 50 Hz\n",
    "avg_eeg_fft[:,np.bitwise_and(w > 49, w < 51)] = 0\n",
    "\n",
    "if opt['detrend']:\n",
    "    avg_eeg = irfft(avg_eeg_fft)\n",
    "    avg_eeg = signal.detrend(avg_eeg,axis=1)\n",
    "# Passband filter\n",
    "if opt['ft-high']:\n",
    "    avg_eeg_fft[:,w > opt['ft-high']] = 0\n",
    "if opt['ft-low']:\n",
    "    avg_eeg_fft[:,w < opt['ft-low']] = 0\n",
    "    avg_eeg = avg_irfft(eeg_fft)\n",
    "\n",
    "avg_eeg = torch.tensor(avg_eeg) #.t()\n",
    "print(avg_eeg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 258, 32]) (640, 40) (640, 120)\n",
      "torch.Size([160, 258, 32]) (160, 40) (160, 120)\n"
     ]
    }
   ],
   "source": [
    "ids = np.random.permutation(a)\n",
    "idx = ids[:int(a/5)]\n",
    "\n",
    "train_eeg = avg_eeg[np.setdiff1d(ids, idx), :, :]\n",
    "train_latent_y = latent_y[np.setdiff1d(ids, idx), :]\n",
    "train_latent_z = latent_z[np.setdiff1d(ids, idx), :]\n",
    "\n",
    "test_eeg = avg_eeg[idx, :, :]\n",
    "test_latent_y = latent_y[idx, :]\n",
    "test_latent_z = latent_z[idx, :]\n",
    "\n",
    "print(train_eeg.shape,train_latent_y.shape,train_latent_z.shape)\n",
    "print(test_eeg.shape, test_latent_y.shape, test_latent_z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 238, 32]) torch.Size([50, 238, 32])\n",
      "torch.Size([10, 238, 32]) torch.Size([10, 238, 32])\n"
     ]
    }
   ],
   "source": [
    "shift = 20\n",
    "# larger window_size, less intersection\n",
    "train_src = train_eeg[:50,:-shift,:]\n",
    "train_tgt = train_eeg[:50,shift:,:]\n",
    "print(train_src.shape, train_tgt.shape)\n",
    "\n",
    "test_src = test_eeg[:10,:-shift,:]\n",
    "test_tgt = test_eeg[:10,shift:,:]\n",
    "print(test_src.shape, test_tgt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model options\n",
    "# opt['lstm-layers'] = 1\n",
    "# opt['lstm-size'] = 35 # 128\n",
    "# opt['embedding-size'] = 35 # 128\n",
    "# opt['num-classes'] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear\"\n",
    "    def __init__(self, d_model):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj1 = nn.Linear(d_model, 128)\n",
    "        self.proj2 = nn.Linear(128, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj2(self.proj1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and Decoder Stacks   \n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention      \n",
    "$$                                                                         \n",
    "   \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V               \n",
    "$$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$    \n",
    "\\mathrm{MultiHead}(Q, K, V) = \\mathrm{Concat}(\\mathrm{head_1}, ..., \\mathrm{head_h})W^O    \\\\                                           \n",
    "    \\text{where}~\\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)                                \n",
    "$$                                                                                                                 \n",
    "\n",
    "Where the projections are parameter matrices $W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ and $W^O \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positionwise Forward\n",
    "$$\\mathrm{FFN}(x)=\\max(0, xW_1 + b_1) W_2 + b_2$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        hh =self.lut(x) * math.sqrt(self.d_model)\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding           \n",
    "In this work, we use sine and cosine functions of different frequencies:       \n",
    "\n",
    "$$PE_{(pos,2i)} = sin(pos / 10000^{2i/d_{\\text{model}}})$$\n",
    "\n",
    "$$PE_{(pos,2i+1)} = cos(pos / 10000^{2i/d_{\\text{model}}})$$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0.0, max_len).unsqueeze(1) # [max_len,1] \n",
    "        div_term = torch.exp(torch.arange(0.0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model options\n",
    "opt['Transformer-layers'] = 3\n",
    "opt['Model-dimensions'] = 32\n",
    "opt['feedford-size'] = 2048 \n",
    "opt['headers'] = 8\n",
    "opt['dropout'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(N=6, d_model=32, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(c(position)),\n",
    "        nn.Sequential(c(position)),\n",
    "        Generator(d_model))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Optimizor\n",
    "$$\n",
    "lrate = d_{\\text{model}}^{-0.5} \\cdot                                                                                                                                                                                                                                                                                                \n",
    "  \\min({step\\_num}^{-0.5},                                                                                                                                                                                                                                                                                                  \n",
    "    {step\\_num} \\cdot {warmup\\_steps}^{-1.5})                                                                                                                                                                                                                                                                               \n",
    "$$                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model_size=32, factor=2, warmup=4000,\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm): \n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous(), y.contiguous()) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item() * norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding Mask for src, Sequence Mask for tgt\n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask =  Variable(torch.ones(src.size(0), 1, src.size(1)) )\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1,:]\n",
    "            self.trg_y = trg[:, 1:,:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = self.trg_y.size(1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    " \n",
    "        tgt_mask = Variable(torch.ones(tgt.size(0), 1, tgt.size(1),dtype = torch.long))\n",
    "        tgt_mask = tgt_mask.type_as(tgt_mask.data) & Variable(subsequent_mask(tgt.size(1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(nbatches,src,tgt):\n",
    "    for i in range(nbatches):\n",
    "        src = Variable(src.float(), requires_grad=False)\n",
    "        tgt = Variable(tgt.float(), requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20], train_loss: 0.002964, test_loss: 0.002772\n",
      "Epoch[2/20], train_loss: 0.002838, test_loss: 0.002543\n",
      "Epoch[3/20], train_loss: 0.002614, test_loss: 0.002245\n",
      "Epoch[4/20], train_loss: 0.002336, test_loss: 0.001902\n",
      "Epoch[5/20], train_loss: 0.002019, test_loss: 0.001529\n",
      "Epoch[6/20], train_loss: 0.001693, test_loss: 0.001164\n",
      "Epoch[7/20], train_loss: 0.001369, test_loss: 0.000865\n",
      "Epoch[8/20], train_loss: 0.001094, test_loss: 0.000668\n",
      "Epoch[9/20], train_loss: 0.000924, test_loss: 0.000555\n",
      "Epoch[10/20], train_loss: 0.000812, test_loss: 0.000494\n",
      "Epoch[11/20], train_loss: 0.000752, test_loss: 0.000467\n",
      "Epoch[12/20], train_loss: 0.000716, test_loss: 0.000455\n",
      "Epoch[13/20], train_loss: 0.000693, test_loss: 0.000433\n",
      "Epoch[14/20], train_loss: 0.000663, test_loss: 0.000393\n",
      "Epoch[15/20], train_loss: 0.000618, test_loss: 0.000344\n",
      "Epoch[16/20], train_loss: 0.000556, test_loss: 0.000296\n",
      "Epoch[17/20], train_loss: 0.000499, test_loss: 0.000250\n",
      "Epoch[18/20], train_loss: 0.000441, test_loss: 0.000207\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model = make_model(opt['Transformer-layers'],opt['Model-dimensions'],opt['feedford-size'],opt['headers'],opt['dropout'])\n",
    "model_opt = NoamOpt(model_size=opt['Model-dimensions'], factor=1, warmup=400,\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "total_epoch = 20\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    loss1 = run_epoch(data_gen(1,train_src,train_tgt), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    \n",
    "    model.eval()\n",
    "    loss2 = run_epoch(data_gen(1,test_src,test_tgt), model, \n",
    "            SimpleLossCompute(model.generator, criterion, None))\n",
    "    print('Epoch[{}/{}], train_loss: {:.6f}, test_loss: {:.6f}'\n",
    "              .format(epoch+1, total_epoch, loss1,loss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
