{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "from lib.eeg_transformer import *\n",
    "from lib.train import *\n",
    "\n",
    "# PyLDS is a Python library for gaussian linear dynamical systems (GLDS) PyLDS also implements\n",
    "# various methods to perform bayesian inference on GLDSs.DefaultLDS (see the cell below) implements a \n",
    "# general purpose linear dynamical system with gaussian noise\n",
    "from pylds.models import DefaultLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# torch.nn is a module that implements varios useful functions and functors to implement flexible and highly\n",
    "# customized neural networks. We will use nn to define neural network modules, different kinds of layers and\n",
    "# diffrent loss functions\n",
    "import torch.nn as nn\n",
    "# torch.nn.functional implements a large variety of activation functions and functional forms of different\n",
    "# neural network layers. Here we will use it for activation functions.\n",
    "import torch.nn.functional as F\n",
    "# torch is the Linear Algebra / Neural Networks library\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Seed the random number generators for reproducible results\n",
    "npr.seed(0)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 300 # number of steps in time\n",
    "INSTS = 1000 # batch-size or the number of instances\n",
    "DOBS = 10 # number of observable variables\n",
    "DLAT = 2 # number of hidden variabkes (latent states)\n",
    "\n",
    "def simple_lds(d_observed=DOBS,d_latent=DLAT,d_input=-1,timesteps=TIMESTEPS,insts=INSTS):\n",
    "    ## d_observed : dimensionality of observed data\n",
    "    ## d_latent : dimensionality of latent states\n",
    "    ## d_input : dimensionality of input data. For d_input=-1 a model with no input is generated\n",
    "    ## timesteps: number of simulated timesteps\n",
    "    ## insts: number of instances\n",
    "    ## instantiating an lds with a random rotational dynamics matrix\n",
    "    \n",
    "    if d_input == -1 :\n",
    "        lds_model = DefaultLDS(d_observed,d_latent,0)\n",
    "        input_data = None\n",
    "    else:\n",
    "        lds_model = DefaultLDS(d_observed,d_latent,d_input)\n",
    "        input_data = npr.randn(insts,timesteps,d_input)\n",
    "    \n",
    "    # initializing the output matrices:\n",
    "    training_set = np.zeros((insts, timesteps, d_observed))\n",
    "    latent_states= np.zeros((insts, timesteps, d_latent))\n",
    "    \n",
    "    # running the model and generating data\n",
    "    for i in range(insts):\n",
    "        training_set[i,:,:], latent_states[i,:,:] = lds_model.generate(timesteps, inputs=input_data)\n",
    "    return training_set, latent_states, lds_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a Model and Generating Data\n",
    "ts,ls,mdl = simple_lds()\n",
    "\n",
    "# Get input_d, output_d, timesteps from the initial dataset\n",
    "input_d, output_d = ts.shape[2], ls.shape[2]\n",
    "timesteps = ts.shape[1]\n",
    "print('input_d:',input_d,'output_d:',output_d,'timesteps:',timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDSDataset(Dataset):\n",
    "    # use boolen value to indicate that the data is for training or testing\n",
    "    def __init__(self,x,y,train,ratio):\n",
    "        self.len = x.shape[0]\n",
    "        self.ratio = ratio\n",
    "        split = int(self.len*self.ratio)\n",
    "        self.x_train = torch.from_numpy(x[:split])\n",
    "        self.y_train = torch.from_numpy(y[:split])\n",
    "        self.x_test = torch.from_numpy(x[split:])\n",
    "        self.y_test = torch.from_numpy(y[split:])\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return int(self.len*self.ratio)\n",
    "        else:\n",
    "            return int(self.len*(1-self.ratio))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            return self.x_train[index], self.y_train[index]\n",
    "        else:\n",
    "            return self.x_test[index], self.y_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and testing set\n",
    "split_ratio = 0.8\n",
    "batch_size = 50\n",
    "dataset_train = LDSDataset(ts,ls,True,split_ratio)\n",
    "dataloader_train = DataLoader(dataset=dataset_train,batch_size=batch_size,shuffle=True)\n",
    "dataset_test = LDSDataset(ts,ls,False,split_ratio)\n",
    "dataloader_test = DataLoader(dataset=dataset_test,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}\n",
    "opt['Transformer-layers'] = 2\n",
    "opt['Model-dimensions'] = 256\n",
    "opt['feedford-size'] = 512\n",
    "opt['headers'] = 8\n",
    "opt['dropout'] = 0.1\n",
    "opt['src_d'] = input_d # input dimension\n",
    "opt['tgt_d'] = output_d # output dimension\n",
    "opt['timesteps'] = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # mean squared error\n",
    "# setup model using hyperparameters defined above\n",
    "model = make_model(opt['src_d'],opt['tgt_d'],opt['Transformer-layers'],opt['Model-dimensions'],opt['feedford-size'],opt['headers'],opt['dropout'])\n",
    "# setup optimization function\n",
    "model_opt = NoamOpt(model_size=opt['Model-dimensions'], factor=1, warmup=400,\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.015, betas=(0.9, 0.98), eps=1e-9))\n",
    "total_epoch = 2000\n",
    "train_losses = np.zeros(total_epoch)\n",
    "test_losses = np.zeros(total_epoch)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    train_loss = run_epoch(data_gen(dataloader_train), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    train_losses[epoch]=train_loss\n",
    "\n",
    "    if (epoch+1)%10 == 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': model_opt.optimizer.state_dict(),\n",
    "                    'loss': train_loss,\n",
    "                    }, 'model_checkpoint/'+str(epoch)+'.pth')            \n",
    "        torch.save(model, 'model_save/model%d.pth'%(epoch)) # save the model\n",
    "\n",
    "    model.eval() # test the model\n",
    "    test_loss = run_epoch(data_gen(dataloader_test), model, \n",
    "            SimpleLossCompute(model.generator, criterion, None))\n",
    "    test_losses[epoch] = test_loss\n",
    "    print('Epoch[{}/{}], train_loss: {:.6f},test_loss: {:.6f}'.format(epoch+1, total_epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a pair of data from test dataset\n",
    "# transfer from tensor to numpy array\n",
    "test_x, test_y = dataset_test.x_test[1].numpy(),dataset_test.y_test[1].numpy()\n",
    "# make a prediction then compare it with its true output\n",
    "test_out, true_out = output_prediction(model,test_x, test_y, max_len=opt['timesteps'], start_symbol=1,output_d=opt['tgt_d'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
